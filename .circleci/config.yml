version: 2.1
orbs:
  aws-cli: circleci/aws-cli@1.4.0

parameters:
  cloudfront_stack_name: 
    type: string
    default: production-distro
  bucket_name:
    type: string
    default: bucket361762484884

commands:
  update_inventory_file:
    steps:
      - run:
          name: Update inventory file with new IPs
          command: |
            aws ec2 describe-instances \
            --query 'Reservations[*].Instances[*].PublicIpAddress' \
            --filters "Name=tag:Name,Values=Ansible" \
            --output text >> inventory

  destroy_environment:
    steps:
      - run:
          name: Destroy environment
          # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
          # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}

  output_environment_state:
    steps:
      - run:
          name: Output inventory data
          command: |
            pwd ; ls -al ; uname ; cat inventory
  
  destroy_cloudfront_environment:
    steps:
      - run:
          name: Destroy cloudfront environment
          # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
          # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name << pipeline.parameters.cloudfront_stack_name >>

jobs:
  smoke_test:
    docker:
      - image: alpine:latest
    steps:
      - run: apk add --update curl
      - destroy_environment
      - run:
          name: smoke test
          command: |
            URL="httpss://blog.udacity.com/"
            # Test if website exists
            if curl -s --head ${URL} 
            then
              return 0
            else
              return 1
            fi


  update_ansible_inventory:
    executor: aws-cli/default
    steps:
      - checkout
      - aws-cli/setup
      - run:
          name: Add inventory header
          command: |
            echo "[all]" > inventory
      - run:
          name: Fetch instance IP address
          command: |
            aws ec2 describe-instances \
            --query 'Reservations[*].Instances[*].PublicIpAddress' \
            --filters "Name=tag:Name,Values=Ansible" \
            --output text >> inventory
      - output_environment_state

  create_infrastructure:
    executor: aws-cli/default
    steps:
      - checkout
      - aws-cli/setup
      - run:
          name: Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
              --template-file template.yml \
              --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
              --region ${AWS_DEFAULT_REGION}

      - run:
          name: Debug failed
          command: |
            aws cloudformation describe-stack-events --stack-name myStack-3a835
          when: on_fail

      - output_environment_state
      - destroy_environment
      
  deploy_cloudfront_cloud_formation_stack:
    executor: aws-cli/default
    steps:
      - checkout
      - aws-cli/setup
      - run:
          name: Create Cloud Cloudformation Stack
          command: |
            aws cloudformation deploy \
              --template-file cloudfront.yml \
              --stack-name << pipeline.parameters.cloudfront_stack_name >> \
              --parameter-overrides PipelineID=<<pipeline.parameters.bucket_name>> \
              --tags project=udapeople &

      - destroy_environment
      - destroy_cloudfront_environment

  # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
  # Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
  create_and_deploy_front_end:
    executor: aws-cli/default
    steps:
      - checkout
      - aws-cli/setup
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
              --template-file bucket.yml \
              --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
              --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
      # Uncomment the step below if yoou wish to upload all contents of the current directory to the S3 bucket
      # - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete

  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt 

  # Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, change its target from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
  # Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name << pipeline.parameters.cloudfront_stack_name >> \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

  # Destroy the previous production version's S3 bucket and CloudFormation stack. 
  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous S3 bucket and CloudFormation stack. 
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive

  # Exercise: Config and Deployment
  configure_infrastructure: 
    docker:
      #- image: python:3.7-alpine3.11
      - image: amazon/aws-cli
    steps:
      - checkout
      - add_ssh_keys:
          # You can get this ID in the section where you registered the SSH Key
          fingerprints: ["7c:73:68:be:eb:fd:e5:0f:1c:82:18:84:09:3c:62:08"]
      - update_inventory_file
      - run:
          name: Install Ansible
          command: |
            yum update -y && \
            amazon-linux-extras install ansible2 -y && \
            ansible --version
      - run:
          name: Run Playbook and Configure server
          command: |
            ansible-playbook main.yml

      - output_environment_state

      - destroy_environment
# Sequential workflow
workflows:
  my_aws_workflows:
    jobs:
      - update_ansible_inventory
      - create_infrastructure:
          requires:
            - update_ansible_inventory
      - configure_infrastructure:
         requires:
           - create_infrastructure
      - deploy_cloudfront_cloud_formation_stack:
          requires:
            - configure_infrastructure
      - create_and_deploy_front_end:
          requires:
            - deploy_cloudfront_cloud_formation_stack
      - get_last_deployment_id:
          requires:
            - create_and_deploy_front_end
      - promote_to_production:
          requires:
            - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - promote_to_production
      # - smoke_test:
      #    requires:
      #      - configure_infrastructure